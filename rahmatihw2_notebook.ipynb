{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "404f1836",
   "metadata": {},
   "source": [
    "# Libraries / Variables / Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0875f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import Levenshtein\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "data=[]                     #keep all docs\n",
    "data_in_bags=[]             #keeps all words in each doc\n",
    "data_in_shingles=[]         #keeps all shingles in each doc                 \n",
    "jac_sim_matrix=np.zeros((491, 491))  #keeps all jac for all pairs\n",
    "Universal_set=set([])  #all the k-shingles in all docs\n",
    "Universal_list=[]\n",
    "one_hundred_hash=[]  #save 100 hash information\n",
    "one_hundred_hash_results=[]  #save 100 hash answers on 491 docs\n",
    "k=3            #size of shingles\n",
    "matrix_text=[] #tells us which text has which words\n",
    "num_of_hash=2\n",
    "num_of_bands=10\n",
    "hash_functions=[]  #keeps all functions in a band\n",
    "bands=[]           #keep all bands and the hash functions within them\n",
    "hash_results_bands=[]    #keeps all the answers of hash functions in all bands\n",
    "hash_pairs=[]      #final result from banding (all two docs with possibly more \n",
    "                   #than 0.3 jaccard similarty)\n",
    "\n",
    "def jaccard(a,b):\n",
    "    return len(a.intersection(b))/len(a.union(b))\n",
    "\n",
    "\n",
    "def minHash(list,a,b,p):    #ax+b mod p daryaft mikone va listi az hameye \n",
    "                            #kalamati ke yek document dare\n",
    "                            # list zir majmue az 3000 kalame madar ast \n",
    "    min=34231\n",
    "    min_index=-1\n",
    "    for i in range (0,len(list)):\n",
    "        temp=(a*list[i]+b)%p\n",
    "        if temp < min:\n",
    "            min= temp\n",
    "    return min\n",
    "\n",
    "\n",
    "def hash_sim(list1,list2):\n",
    "    count=0\n",
    "    for i in range (0,len(list1)):\n",
    "        if list1[i]==list2[i]:\n",
    "            count+=1\n",
    "    return round(count/len(list1),4)\n",
    "            \n",
    "\n",
    "def partition(hash_results):      #natayej hash 491 doc ra besurate list migirad \n",
    "                                  #va mige koduma ba ham moghayese beshan \n",
    "                                  #(tedad hash ha mitavanad harchi bashad)\n",
    "    spot=[0]*491\n",
    "    partitions=[]\n",
    "    for i in range (0,491):\n",
    "        if spot[i]==0:\n",
    "            gather=[]\n",
    "            spot[i]=1\n",
    "            gather.append(i)\n",
    "            for j in range (i+1,491):\n",
    "                if hash_results[j]==hash_results[i]:\n",
    "                    spot[j]=1\n",
    "                    gather.append(j)\n",
    "            partitions.append(gather)\n",
    "    return partitions\n",
    "\n",
    "\n",
    "def pair_producer(list):   #yek listi as list haro migire (natijeye partition=input) \n",
    "                           #va zoj hayi ke bayad\n",
    "                           #bayad moghayese beshan vali hanuz tu hash_pairs nistand \n",
    "                           #ro vared hash_pairs mikone\n",
    "        for i in range (0,len(list)):\n",
    "            for j in range (0,len(list[i])):\n",
    "                for k in range (j+1,len(list[i])):\n",
    "                    tup=(list[i][j],list[i][k])\n",
    "                    check=tup in hash_pairs\n",
    "                    if check==False:\n",
    "                        hash_pairs.append(tup)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa365e2",
   "metadata": {},
   "source": [
    "# Read all the data into a list called data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c82fa04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,491):\n",
    "    file=open('sample/'+ str(i)+'.txt', 'r', encoding=\"utf8\")\n",
    "    data.append(file.read())\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc5f2c8",
   "metadata": {},
   "source": [
    "# Calculating edit distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "515dc907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.0 minutes to calculate edit distances and their maximum pairs\n"
     ]
    }
   ],
   "source": [
    "file1=open('sample/distances.txt', 'w')\n",
    "file2= open('sample/max_distances.txt', 'w')\n",
    "file1.write(\"Pairs    Edit_Similarity\\n\")\n",
    "file2.write(\"MaxPairs  Max Edit_Similarity\\n\")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range (0,491):\n",
    "    max_sim=0\n",
    "    max_sim_index=-1\n",
    "    \n",
    "    for j in range (i+1,491):\n",
    "        max_string_length=max(len(data[i]),len(data[j]))\n",
    "        edit_similarity=\\\n",
    "        (max_string_length - Levenshtein.distance(data[i],data[j]))/max_string_length\n",
    "        \n",
    "        if(edit_similarity>=max_sim):\n",
    "            max_sim=edit_similarity\n",
    "            max_sim_index=j\n",
    "        \n",
    "        file1.write(str(i)+\" \"+str(j)+\"        \"+str(round(edit_similarity, 4))+\"\\n\")\n",
    "        \n",
    "    file2.write(str(i)+\" \"+str(max_sim_index)+\"        \"+str(round(max_sim, 4))+\"\\n\")\n",
    "        \n",
    "\n",
    "file1.close()\n",
    "file2.close()\n",
    "end = time.time()\n",
    "\n",
    "print('It took', round((end-start)/60,2), \\\n",
    "      'minutes to calculate edit distances and their maximum pairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8d6c41",
   "metadata": {},
   "source": [
    "# Calculating Jaccard  (bags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7916fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 15.56  seconds to calculate Jaccard distances and their maximum pairs (BAG OF WORDS)\n"
     ]
    }
   ],
   "source": [
    "for j in range (0,491):\n",
    "    words=data[j].split()\n",
    "    data_in_bags.append(words)\n",
    "\n",
    "    \n",
    "file1=open('sample/jac_sim_bags.txt', 'w')\n",
    "file2= open('sample/max_jac_sim_bags.txt', 'w')\n",
    "file1.write(\"Pairs    Jac_Similarity_Bags\\n\")\n",
    "file2.write(\"MaxPairs  Max Jac_Similarity_Bags\\n\")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range (0,491):\n",
    "    max_jac_sim=0\n",
    "    max_jac_sim_index=-1\n",
    "    \n",
    "    for j in range (i+1,491):        \n",
    "        jac_similarity= jaccard(set(data_in_bags[i]),set(data_in_bags[j]))\n",
    "        \n",
    "        if(jac_similarity>=max_jac_sim):\n",
    "            max_jac_sim=jac_similarity\n",
    "            max_jac_sim_index=j\n",
    "        \n",
    "        file1.write(str(i)+\" \"+str(j)+\"        \"+str(round(jac_similarity, 4))+\"\\n\")\n",
    "        \n",
    "    file2.write(str(i)+\" \"+str(max_jac_sim_index)+\"        \"+str(round(max_jac_sim, 4))+\"\\n\")\n",
    "        \n",
    "\n",
    "file1.close()\n",
    "file2.close()\n",
    "end = time.time()\n",
    "\n",
    "print('It took', round((end-start),2), ' seconds to calculate Jaccard distances\\\n",
    " and their maximum pairs (BAG OF WORDS)')        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c993be",
   "metadata": {},
   "source": [
    "# Calculating Jaccard  (Shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eb21df1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 29.06  seconds to calculate Jaccard distances and their maximum pairs (3-SHINGLES)\n"
     ]
    }
   ],
   "source": [
    "for j in range (0,491):\n",
    "    myset=set([])\n",
    "    for i in range(1,len(data[j])-k-1):\n",
    "        shingle=data[j][i:i+k]\n",
    "        temp_str=''        \n",
    "        for r in range(k):\n",
    "            temp_str+=str(ord(shingle[r]))\n",
    "        myset.add(int(temp_str))\n",
    "    data_in_shingles.append(myset)\n",
    "    \n",
    "    \n",
    "file1=open('sample/jac_sim_Shingles.txt', 'w')\n",
    "file2= open('sample/max_jac_sim_Shingles.txt', 'w')\n",
    "file1.write(\"Pairs    Jac_Similarity_Shingles\\n\")\n",
    "file2.write(\"MaxPairs  Max Jac_Similarity_shingles\\n\")\n",
    "\n",
    "start = time.time()\n",
    "for i in range (0,491):\n",
    "    max_jac_sim=0\n",
    "    max_jac_sim_index=-1\n",
    "    \n",
    "    for j in range (i+1,491):        \n",
    "        jac_similarity= jaccard(data_in_shingles[i],data_in_shingles[j])\n",
    "        \n",
    "        if(jac_similarity>=max_jac_sim):\n",
    "            max_jac_sim=jac_similarity\n",
    "            max_jac_sim_index=j\n",
    "        \n",
    "        file1.write(str(i)+\" \"+str(j)+\"        \"+str(round(jac_similarity, 4))+\"\\n\")\n",
    "        jac_sim_matrix[i][j]=round(jac_similarity, 4)\n",
    "        \n",
    "    file2.write(str(i)+\" \"+str(max_jac_sim_index)+\"        \"+str(round(max_jac_sim, 4))+\"\\n\")\n",
    "        \n",
    "\n",
    "file1.close()\n",
    "file2.close()\n",
    "end = time.time()\n",
    "\n",
    "print('It took', round((end-start),2), ' seconds to calculate\\\n",
    " Jaccard distances and their maximum pairs (3-SHINGLES)')        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0cdf45",
   "metadata": {},
   "source": [
    "# 100 hash functions to make comparison easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "974545ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used to compute universal words:  9.123588562011719\n",
      "time used to compute membership of 3-shingles in documents  5.899840831756592\n"
     ]
    }
   ],
   "source": [
    "n=34231 #first prime after (34,227= size of Universal set)\n",
    "\n",
    "start = time.time()\n",
    "for j in range (0,491):\n",
    "    for i in range(1,len(data[j])-k-1):\n",
    "        shingle=data[j][i:i+k]\n",
    "        temp_str=''         \n",
    "        for r in range(k):\n",
    "            temp_str+=str(ord(shingle[r]))  \n",
    "        mytuple=(shingle,int(temp_str))    \n",
    "        Universal_set.add(mytuple)\n",
    "        \n",
    "end = time.time()\n",
    "print('time used to compute universal words: ', end-start)\n",
    "\n",
    "Universal_list=list(Universal_set)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range (0,491):\n",
    "    column=[]\n",
    "    for j in range (0,34227): \n",
    "        if Universal_list[j][1] in data_in_shingles[i]: \n",
    "            column.append(j)\n",
    "    matrix_text.append(column)        \n",
    "            \n",
    "end = time.time()\n",
    "\n",
    "print('time used to compute membership of 3-shingles in documents ', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8dac3a",
   "metadata": {},
   "source": [
    "produce 100 random hash functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "32cf2b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used to compute 100 hash results on 491 texts:  21.58146333694458\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "while True:\n",
    "    a=random.randint(1,100)\n",
    "    b=random.randint(1,100)\n",
    "    tup=(a,b)\n",
    "\n",
    "    check=tup in one_hundred_hash\n",
    "\n",
    "    if check==False:\n",
    "        count+=1\n",
    "        one_hundred_hash.append(tup)\n",
    "    if count==100: \n",
    "        break\n",
    "#print(tenhash)\n",
    "\n",
    "one_hundred_hash_result=[]\n",
    "start = time.time()\n",
    "for k in range (0,491):\n",
    "        temp=[]\n",
    "        for j in range (0,100):\n",
    "            temp.append(minHash(matrix_text[k],one_hundred_hash[j][0],one_hundred_hash[j][1],34231))\n",
    "        one_hundred_hash_result.append(temp)\n",
    "end = time.time()\n",
    "\n",
    "print('time used to compute 100 hash results on 491 texts: ', end-start) \n",
    "#print(len(tenhash_result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335536e0",
   "metadata": {},
   "source": [
    "# Estimate Jaccard Similarities using fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5c251681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 2.04  seconds to calculate Jaccard distances and their maximum pairs using 100 hash_estimates\n"
     ]
    }
   ],
   "source": [
    "file1=open('sample/jac_sim_Shingles_hash_estimate.txt', 'w')\n",
    "file2= open('sample/max_jac_sim_Shingles_hash_estimate.txt', 'w')\n",
    "file1.write(\"Pairs    Jac_Similarity_Shingles_hash_estimate\\n\")\n",
    "file2.write(\"MaxPairs  Max Jac_Similarity_shingles_hash_estimate\\n\")\n",
    "\n",
    "start = time.time()\n",
    "for i in range (0,491):\n",
    "    max_jac_sim=0\n",
    "    max_jac_sim_index=-1\n",
    "    \n",
    "    for j in range (i+1,491):        \n",
    "        jac_similarity= hash_sim(one_hundred_hash_result[i],one_hundred_hash_result[j])\n",
    "        \n",
    "        if(jac_similarity>=max_jac_sim):\n",
    "            max_jac_sim=jac_similarity\n",
    "            max_jac_sim_index=j\n",
    "        \n",
    "        file1.write(str(i)+\" \"+str(j)+\"        \"+str(jac_similarity)+\"\\n\")\n",
    "\n",
    "        \n",
    "    file2.write(str(i)+\" \"+str(max_jac_sim_index)+\"        \"+str(max_jac_sim)+\"\\n\")\n",
    "        \n",
    "\n",
    "file1.close()\n",
    "file2.close()\n",
    "end = time.time()\n",
    "\n",
    "print('It took', round((end-start),2), ' seconds to calculate\\\n",
    " Jaccard distances and their maximum pairs using 100 hash_estimates')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318ca8b",
   "metadata": {},
   "source": [
    "# MinHash and Banding Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9722622f",
   "metadata": {},
   "source": [
    "Create as many Hash Functions as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f215bf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used to create the hash functions in all bands: 0.0  seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "hash_functions=[]\n",
    "bands=[]\n",
    "start = time.time()\n",
    "for k in range(0,num_of_bands):\n",
    "    count=0\n",
    "    hash_for_this_band=[]\n",
    "    while True:\n",
    "        \n",
    "        a=random.randint(1,100)\n",
    "        b=random.randint(1,100)\n",
    "        tup=(a,b)\n",
    "        \n",
    "        check=tup in hash_functions\n",
    "        \n",
    "        if check==False:\n",
    "            count+=1\n",
    "            hash_functions.append(tup)\n",
    "            hash_for_this_band.append(tup)\n",
    "            #print(tup)\n",
    "        if count==num_of_hash: \n",
    "            bands.append(hash_for_this_band)\n",
    "            break\n",
    "end = time.time()\n",
    "\n",
    "print('time used to create the hash functions in all bands:\\\n",
    "', round((end-start),2), ' seconds')         \n",
    "t1=end-start\n",
    "#print(bands)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76766601",
   "metadata": {},
   "source": [
    "calculating the results of all hash functions in bands on all 491 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "995cb81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used to compute hash results in bands on 491 texts:  4.37  seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for k in range (0,num_of_bands):\n",
    "    hash_results=[]\n",
    "    for i in range(0,491):\n",
    "        temp=[]\n",
    "        for j in range (0,num_of_hash):\n",
    "            temp.append(\\\n",
    "            minHash(matrix_text[i],bands[k][j][0],bands[k][j][1],34231))\n",
    "        hash_results.append(temp)\n",
    "    hash_results_bands.append(hash_results)  \n",
    "end = time.time()\n",
    "\n",
    "print('time used to compute hash results in bands \\\n",
    "on 491 texts: ', round((end-start),2), ' seconds') \n",
    "t2=end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6138fb",
   "metadata": {},
   "source": [
    "# Extract the pairs from the similar hash results in bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aeb98400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 31.15 seconds to calculate pairs from minhash results\n",
      " bands= 10 hash functions=  2\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(0,num_of_bands):\n",
    "    a= partition(hash_results_bands[i])\n",
    "    pair_producer(a)\n",
    "end = time.time()\n",
    "print('It took', round((end-start),2), 'seconds \\\n",
    "to calculate pairs from minhash results\\n bands=',num_of_bands, \\\n",
    "      'hash functions= ', num_of_hash) \n",
    "t3=end-start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a6f46",
   "metadata": {},
   "source": [
    "# Check False Positives and False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "43f691d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real positives:  47760\n",
      "real negatives:  72535\n"
     ]
    }
   ],
   "source": [
    "pos=0\n",
    "neg=0\n",
    "for i in range (0,491):\n",
    "    for j in range (i+1,491):\n",
    "        if jac_sim_matrix[i][j]>=0.3:\n",
    "            pos+=1\n",
    "        else:\n",
    "            neg+=1\n",
    "\n",
    "print('real positives: ', pos)\n",
    "print('real negatives: ', neg)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a7c609ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#{False Positive}      19657\n",
      "َ#{All selected Pairs}  45116\n",
      "#{False Negative}      22301\n"
     ]
    }
   ],
   "source": [
    "false_positive=0\n",
    "false_negative=0\n",
    "checked_pairs_matrix=np.zeros((491, 491))\n",
    "\n",
    "for i in range (0,len(hash_pairs)):\n",
    "    checked_pairs_matrix[hash_pairs[i][0]][hash_pairs[i][1]]=-1\n",
    "    if jac_sim_matrix[hash_pairs[i][0]][hash_pairs[i][1]]<0.3:\n",
    "        false_positive+=1\n",
    "\n",
    "        \n",
    "for i in range (0,491):\n",
    "    for j in range (i+1,491):\n",
    "        if checked_pairs_matrix[i,j]==0:\n",
    "            if jac_sim_matrix[i][j]>=0.3:\n",
    "                false_negative+=1\n",
    "\n",
    "print(\"#{False Positive}     \", false_positive)\n",
    "print(\"َ#{All selected Pairs} \",len(hash_pairs))\n",
    "print(\"#{False Negative}     \", false_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "09954b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score  0.274\n",
      "time  49.96 seconds\n"
     ]
    }
   ],
   "source": [
    "tp= len(hash_pairs)-false_positive\n",
    "prec= tp / (tp + false_positive)\n",
    "rec= tp / (tp + false_negative)\n",
    "f_one_score= 1/ ((1/rec)+(1/prec))\n",
    "print(\"f1_score \", round(f_one_score,3))\n",
    "print(\"time \", round (t1+t2+t3+14.4,2), 'seconds' )  #14.4 was time to calculate \n",
    "                                                    #universal set and shingles memberships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f1327b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
